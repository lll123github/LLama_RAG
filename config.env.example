# 统一的Llama + RAG搜索服务配置文件
# 复制此文件为 config.env 并修改相应的值

# ==================== 服务端口 ====================
# Llama服务器端口
LLAMA_PORT=8000

# 统一应用端口
UNIFIED_PORT=5000

# ==================== 模型配置 ====================
# 模型文件路径
MODEL_PATH=/root/models/Qwen3-0.6B-Q8_0.gguf

# 聊天模板路径
LLAMA_TEMPLATE=/root/llama.cpp/models/templates/qwen3_nonthinking.jinja

# ==================== 性能优化（ARM64设备） ====================
# 线程数（推荐：2-4）
LLAMA_THREADS=2

# 上下文长度（推荐：1024-4096）
LLAMA_CONTEXT=2048

# ==================== 日志配置 ====================
# 日志级别：DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# 日志文件路径
LOG_DIR=/tmp

# ==================== 内容搜索配置 ====================
# 内容文件夹路径
CONTENT_DIR=rag/content

# 搜索缓存文件
SEARCH_CACHE=rag/search_results.json

# ==================== 高级配置 ====================
# Llama服务器地址（用于代理）
LLAMA_SERVER_URL=http://localhost:8000

# Flask调试模式（生产环境应设为False）
FLASK_DEBUG=False

# 最大请求体大小（字节）
MAX_CONTENT_LENGTH=16777216

# ==================== 可选功能 ====================
# 启用搜索功能
ENABLE_SEARCH=True

# 启用聊天功能
ENABLE_CHAT=True

# 启用系统信息API
ENABLE_SYSTEM_INFO=True

